# id: aoanet
caption_model: aoa

# AOA config
refine: 1
refine_aoa: 1
use_ff: 0
decoder_type: AoA
use_multi_head: 2
num_heads: 8
multi_head_scale: 1
mean_feats: 1
ctx_drop: 1
dropout_aoa: 0.3

label_smoothing: 0.2

# input_json: data/cocotalk.json
# input_label_h5: data/cocotalk_label.h5
# input_fc_dir: data/cocobu_fc
# input_att_dir: data/cocobu_att
# input_box_dir: data/cocobu_box

# input_json: data/data_daisi/daisi_afterprepro.json
# input_label_h5: data/data_daisi/daisi_afterprepro_label.h5
# input_fc_dir: data/data_daisi/daisi_resnet18_feat512_fc
# input_att_dir: data/data_daisi/daisi_resnet18_feat512_att
# input_box_dir: None

input_json: data/data_miccai18/miccai18_afterprepro.json
input_label_h5: data/data_miccai18/miccai18_afterprepro_label.h5
input_att_dir: data/data_miccai18/miccai18_resnet18_feat512_att
input_fc_dir: data/data_miccai18/miccai18_resnet18_feat512_fc
input_box_dir: None

# seq_per_img: 5
seq_per_img: 1

# batch_size: 10
batch_size: 9

beam_size: 1
# learning_rate: 0.0002
learning_rate: 0.0005
num_layers: 2

# input_encoding_size: 1024
# rnn_size: 1024

# added by mengya 
#================ 512 set ===============#
fc_feat_size: 512
att_feat_size: 512
input_encoding_size: 512
# rnn_size: 512
rnn_size: 2048
#========================================#

learning_rate_decay_start: 0
scheduled_sampling_start: 0

# save_checkpoint_every: 6000
save_every_epoch: 1

language_eval: 1
val_images_use: -1
# max_epochs: 25
max_epochs: 100

scheduled_sampling_increase_every: 5
scheduled_sampling_max_prob: 0.5
learning_rate_decay_every: 3